{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This example is just to show the Multilabel clafficatoin with neural networks in Tensoflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **So, I didn't given importance for accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\progammefiles\\python\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,classification,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os,glob\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df=pd.read_csv('E:/Machine_learning/DataSets/emg-4/0.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3     4     5      6     7     8    9  ...    55    56  \\\n",
       "0  26.0  4.0  5.0  8.0  -1.0 -13.0 -109.0 -66.0  -9.0  2.0 ... -28.0  61.0   \n",
       "1 -47.0 -6.0 -5.0 -7.0  13.0  -1.0   35.0 -10.0  10.0 -4.0 ... -25.0  47.0   \n",
       "2 -19.0 -8.0 -8.0 -8.0 -21.0  -6.0  -79.0  12.0   0.0  5.0 ... -83.0   7.0   \n",
       "3   2.0  3.0  0.0  2.0   0.0  22.0  106.0 -14.0 -16.0 -2.0 ... -38.0 -11.0   \n",
       "4   6.0  0.0  0.0 -2.0 -14.0  10.0  -51.0   5.0   7.0  0.0 ...  38.0 -35.0   \n",
       "\n",
       "    57   58    59    60    61     62    63  64  \n",
       "0  4.0  8.0   5.0   4.0  -7.0  -59.0  16.0   0  \n",
       "1  6.0  6.0   5.0  13.0  21.0  111.0  15.0   0  \n",
       "2  7.0  1.0  -8.0   7.0  21.0  114.0  48.0   0  \n",
       "3  4.0  7.0  11.0  33.0  39.0  119.0  43.0   0  \n",
       "4 -8.0  2.0   6.0 -13.0 -24.0 -112.0 -69.0   0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The sources files contains into fours files like *.CSV, and in the file doesn't contain any columns names and class, so we taken column names like below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['col'+str(i+1) for i in range(64)]\n",
    "cols.append('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files=glob.glob(os.path.join('E:/Machine_learning/DataSets/emg-4/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "np_array=[]\n",
    "for i in all_files:\n",
    "    df=pd.read_csv(i,header=None,index_col=None)\n",
    "    np_array.append(df.as_matrix())\n",
    "\n",
    "df=pd.DataFrame(np.vstack(np_array),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11678, 65)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  col4  col5  col6   col7  col8  col9  col10  ...    col56  \\\n",
       "0  26.0   4.0   5.0   8.0  -1.0 -13.0 -109.0 -66.0  -9.0    2.0  ...    -28.0   \n",
       "1 -47.0  -6.0  -5.0  -7.0  13.0  -1.0   35.0 -10.0  10.0   -4.0  ...    -25.0   \n",
       "2 -19.0  -8.0  -8.0  -8.0 -21.0  -6.0  -79.0  12.0   0.0    5.0  ...    -83.0   \n",
       "3   2.0   3.0   0.0   2.0   0.0  22.0  106.0 -14.0 -16.0   -2.0  ...    -38.0   \n",
       "4   6.0   0.0   0.0  -2.0 -14.0  10.0  -51.0   5.0   7.0    0.0  ...     38.0   \n",
       "\n",
       "   col57  col58  col59  col60  col61  col62  col63  col64  class  \n",
       "0   61.0    4.0    8.0    5.0    4.0   -7.0  -59.0   16.0    0.0  \n",
       "1   47.0    6.0    6.0    5.0   13.0   21.0  111.0   15.0    0.0  \n",
       "2    7.0    7.0    1.0   -8.0    7.0   21.0  114.0   48.0    0.0  \n",
       "3  -11.0    4.0    7.0   11.0   33.0   39.0  119.0   43.0    0.0  \n",
       "4  -35.0   -8.0    2.0    6.0  -13.0  -24.0 -112.0  -69.0    0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**being classfication problem, So class column divided into four columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df.drop(['class'],axis=1),\n",
    "              pd.DataFrame(np.array(pd.get_dummies(df['class'])),columns=['class1','class2','class3','class4'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  col4  col5  col6   col7  col8  col9  col10   ...    \\\n",
       "0  26.0   4.0   5.0   8.0  -1.0 -13.0 -109.0 -66.0  -9.0    2.0   ...     \n",
       "1 -47.0  -6.0  -5.0  -7.0  13.0  -1.0   35.0 -10.0  10.0   -4.0   ...     \n",
       "2 -19.0  -8.0  -8.0  -8.0 -21.0  -6.0  -79.0  12.0   0.0    5.0   ...     \n",
       "3   2.0   3.0   0.0   2.0   0.0  22.0  106.0 -14.0 -16.0   -2.0   ...     \n",
       "4   6.0   0.0   0.0  -2.0 -14.0  10.0  -51.0   5.0   7.0    0.0   ...     \n",
       "\n",
       "   col59  col60  col61  col62  col63  col64  class1  class2  class3  class4  \n",
       "0    8.0    5.0    4.0   -7.0  -59.0   16.0       1       0       0       0  \n",
       "1    6.0    5.0   13.0   21.0  111.0   15.0       1       0       0       0  \n",
       "2    1.0   -8.0    7.0   21.0  114.0   48.0       1       0       0       0  \n",
       "3    7.0   11.0   33.0   39.0  119.0   43.0       1       0       0       0  \n",
       "4    2.0    6.0  -13.0  -24.0 -112.0  -69.0       1       0       0       0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col55</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  col4  col5  col6   col7  col8  col9  col10  ...    col55  \\\n",
       "0  26.0   4.0   5.0   8.0  -1.0 -13.0 -109.0 -66.0  -9.0    2.0  ...     21.0   \n",
       "1 -47.0  -6.0  -5.0  -7.0  13.0  -1.0   35.0 -10.0  10.0   -4.0  ...   -105.0   \n",
       "2 -19.0  -8.0  -8.0  -8.0 -21.0  -6.0  -79.0  12.0   0.0    5.0  ...   -128.0   \n",
       "3   2.0   3.0   0.0   2.0   0.0  22.0  106.0 -14.0 -16.0   -2.0  ...    -54.0   \n",
       "4   6.0   0.0   0.0  -2.0 -14.0  10.0  -51.0   5.0   7.0    0.0  ...     60.0   \n",
       "\n",
       "   col56  col57  col58  col59  col60  col61  col62  col63  col64  \n",
       "0  -28.0   61.0    4.0    8.0    5.0    4.0   -7.0  -59.0   16.0  \n",
       "1  -25.0   47.0    6.0    6.0    5.0   13.0   21.0  111.0   15.0  \n",
       "2  -83.0    7.0    7.0    1.0   -8.0    7.0   21.0  114.0   48.0  \n",
       "3  -38.0  -11.0    4.0    7.0   11.0   33.0   39.0  119.0   43.0  \n",
       "4   38.0  -35.0   -8.0    2.0    6.0  -13.0  -24.0 -112.0  -69.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(['class1','class2','class3','class4'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class1  class2  class3  class4\n",
       "0       1       0       0       0\n",
       "1       1       0       0       0\n",
       "2       1       0       0       0\n",
       "3       1       0       0       0\n",
       "4       1       0       0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[['class1','class2','class3','class4']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11678, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11678, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.astype(float)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.1, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state=42)\n",
    "#X_train=pd.DataFrame(X_train,columns=X.columns)\n",
    "#X_test=pd.DataFrame(X_test,columns=X.columns)\n",
    "#y_train=pd.DataFrame(y_train,columns=y.columns)\n",
    "#y_test=pd.DataFrame(y_test,columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col55</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>-20.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-94.0</td>\n",
       "      <td>-17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col1  col2  col3  col4  col5  col6  col7  col8  col9  col10  ...    \\\n",
       "4684 -17.0  -4.0   1.0   1.0  -8.0 -35.0  -1.0   1.0  -1.0    0.0  ...     \n",
       "960    5.0  -4.0   6.0  12.0   4.0   0.0 -57.0 -11.0  -7.0    9.0  ...     \n",
       "2009  14.0   0.0  -5.0  -8.0 -12.0 -27.0 -65.0 -18.0  11.0  -12.0  ...     \n",
       "1579 -20.0  -9.0  -3.0 -14.0  -7.0  -2.0 -56.0  -3.0  -8.0   17.0  ...     \n",
       "883   16.0  10.0  -3.0 -14.0 -13.0  -3.0  56.0  -2.0  12.0    0.0  ...     \n",
       "\n",
       "      col55  col56  col57  col58  col59  col60  col61  col62  col63  col64  \n",
       "4684    2.0    1.0    3.0    1.0    2.0    2.0  -11.0  -28.0   -1.0   -1.0  \n",
       "960    99.0   60.0    1.0    5.0   14.0    7.0   14.0   15.0  -53.0   41.0  \n",
       "2009  -16.0  -11.0   10.0  -21.0    5.0   13.0   -3.0   -7.0   25.0    7.0  \n",
       "1579  -50.0   -8.0   -4.0   -4.0    0.0   17.0  -22.0  -38.0  -94.0  -17.0  \n",
       "883    97.0    2.0   10.0    3.0   -3.0   -8.0  -21.0   24.0   10.0    9.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxScaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minMaxScaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col55</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436123</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.530516</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.507874</td>\n",
       "      <td>0.459916</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.489712</td>\n",
       "      <td>0.545852</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.490040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533040</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.489960</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.460630</td>\n",
       "      <td>0.434599</td>\n",
       "      <td>0.585470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.563319</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.540670</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.657371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572687</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.527559</td>\n",
       "      <td>0.511737</td>\n",
       "      <td>0.381526</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.449782</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.459330</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.521912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422907</td>\n",
       "      <td>0.489691</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.460905</td>\n",
       "      <td>0.524017</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.426295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581498</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.477912</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.514768</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.537190</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.554585</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.529880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col1      col2      col3      col4      col5      col6      col7  \\\n",
       "0  0.436123  0.515464  0.507463  0.598425  0.530516  0.349398  0.498039   \n",
       "1  0.533040  0.515464  0.582090  0.685039  0.586854  0.489960  0.278431   \n",
       "2  0.572687  0.536082  0.417910  0.527559  0.511737  0.381526  0.247059   \n",
       "3  0.422907  0.489691  0.447761  0.480315  0.535211  0.481928  0.282353   \n",
       "4  0.581498  0.587629  0.447761  0.480315  0.507042  0.477912  0.721569   \n",
       "\n",
       "       col8      col9     col10    ...        col55     col56     col57  \\\n",
       "0  0.507874  0.459916  0.547009    ...     0.509804  0.533058  0.489712   \n",
       "1  0.460630  0.434599  0.585470    ...     0.890196  0.776860  0.481481   \n",
       "2  0.433071  0.510549  0.495726    ...     0.439216  0.483471  0.518519   \n",
       "3  0.492126  0.430380  0.619658    ...     0.305882  0.495868  0.460905   \n",
       "4  0.496063  0.514768  0.547009    ...     0.882353  0.537190  0.518519   \n",
       "\n",
       "      col58     col59     col60     col61     col62     col63     col64  \n",
       "0  0.545852  0.640000  0.591667  0.421053  0.392157  0.498039  0.490040  \n",
       "1  0.563319  0.800000  0.633333  0.540670  0.560784  0.294118  0.657371  \n",
       "2  0.449782  0.680000  0.683333  0.459330  0.474510  0.600000  0.521912  \n",
       "3  0.524017  0.613333  0.716667  0.368421  0.352941  0.133333  0.426295  \n",
       "4  0.554585  0.573333  0.508333  0.373206  0.596078  0.541176  0.529880  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=minMaxScaler.transform(X_train)\n",
    "X_train=pd.DataFrame(X_train,columns=X.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=minMaxScaler.transform(X_test)\n",
    "X_test=pd.DataFrame(X_test,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10510, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class1  class2  class3  class4\n",
       "4684     0.0     1.0     0.0     0.0\n",
       "960      1.0     0.0     0.0     0.0\n",
       "2009     1.0     0.0     0.0     0.0\n",
       "1579     1.0     0.0     0.0     0.0\n",
       "883      1.0     0.0     0.0     0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[9340:9342].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[9341:9342].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[800:802].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10510"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Creating Batch for data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class batch_data:\n",
    "    \n",
    "    Previous_size=0\n",
    "    \n",
    "    def __init__(self,X_input,y_input):\n",
    "        self.X=X_input\n",
    "        self.y=y_input\n",
    "    \n",
    "    def next_batch(self,size):\n",
    "        #Previous_size=Previous_size+self.size\n",
    "        start_loc=self.Previous_size\n",
    "        end_loc=self.Previous_size+size\n",
    "        self.Previous_size=end_loc\n",
    "        if len(self.X)<end_loc:\n",
    "            self.Previous_size=0\n",
    "            return self.X[len(self.X)-size:len(self.X)],self.y[len(self.X)-size:len(self.X)]\n",
    "        if len(self.X)==end_loc:\n",
    "            self.Previous_size=0\n",
    "        return self.X[start_loc:end_loc],self.y[start_loc:end_loc]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_data=batch_data(X_train,y_train) \n",
    "test_batch_data=batch_data(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Place holders for input Tensor and output Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true=tf.placeholder(tf.float32,shape=[None,64])\n",
    "y_true=tf.placeholder(tf.float32,shape=[None,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "batch_size=32\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wt_bi(shape):\n",
    "    return tf.Variable(tf.ones(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=create_wt_bi([64,32])\n",
    "b1=create_wt_bi([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2=create_wt_bi([32,16])\n",
    "b2=create_wt_bi([16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo=create_wt_bi([16,4])\n",
    "bo=create_wt_bi([4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Graph for Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer1=tf.add(tf.matmul(X_true,w1),b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer2=tf.matmul(hidden_layer1,w2)+b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out=tf.add(tf.matmul(hidden_layer2,wo),bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy=tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_out)\n",
    "#entropy=tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=optimizer.minimize(loss)\n",
    "saver=tf.train.Saver(max_to_keep=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training (sess,train,y_out,X_train,y_train,batch_size=32,X_test=None,y_test=None,epochs=1):\n",
    "    \n",
    "    #Creating object batch data\n",
    "    train_batch_data=batch_data(X_train,y_train)\n",
    "    test_batch_data=batch_data(X_test,y_test)\n",
    "    \n",
    "    #Cal for steps for each epcoh\n",
    "    steps_for_epoch=math.ceil(len(X_train)/batch_size)\n",
    "    \n",
    "    test_scores=[]\n",
    "    train_scores=[]\n",
    "    loss_value=[]\n",
    "    \n",
    "    for i in range(0,epochs):\n",
    "        j=0\n",
    "        while(True):\n",
    "            \n",
    "            #Getting X_train,y_train data\n",
    "            X_feed,y_feed=train_batch_data.next_batch(batch_size)\n",
    "            \n",
    "            #Training model\n",
    "            _,loss_tr=sess.run([train,loss],feed_dict={X_true:X_feed,y_true:y_feed})\n",
    "            \n",
    "            j=j+1\n",
    "            \n",
    "            #Checking epochs is completed or not\n",
    "            if j>=steps_for_epoch:\n",
    "                \n",
    "                print(i+1, 'epochs is completed')\n",
    "                print('Loss:',loss_tr)\n",
    "                loss_value.append(loss_tr)\n",
    "                \n",
    "                #Training Predictions\n",
    "                train_op=sess.run(tf.argmax(y_out,1),feed_dict={X_true:X_train})\n",
    "                \n",
    "                #Training Accuracy\n",
    "                train_acc_score=accuracy_score(np.argmax(np.array(y_train),axis=1),train_op)\n",
    "                print('Accuracy score:',accuracy_score(np.argmax(np.array(y_train),axis=1),train_op))\n",
    "                \n",
    "                #if X_test!=None:\n",
    "                \n",
    "                #Testing Predicions\n",
    "                test_op=sess.run(tf.arg_max(y_out,1),feed_dict={X_true:X_test})\n",
    "                \n",
    "                #Testing accuracy\n",
    "                test_acc_score=accuracy_score(np.argmax(np.array(y_test),axis=1),test_op)\n",
    "                print('Test Accuracy Score: ',accuracy_score(np.argmax(np.array(y_test),axis=1),test_op))\n",
    "                \n",
    "                train_scores.append(train_acc_score)\n",
    "                test_scores.append(test_acc_score)\n",
    "                \n",
    "                #Saving checkpoints for each epoch\n",
    "                checpoint='E:/Machine_learning/savingModel/tensorflowcheckpioints/classfication_'+str(int(i+1))+'epcohs.ckpt'\n",
    "                saver.save(sess,checpoint)\n",
    "                #print(i)\n",
    "                break\n",
    "    \n",
    "    return train_scores,test_scores,loss_value\n",
    "                #return train_acc_score,None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epochs is completed\n",
      "Loss: 1.4026544\n",
      "Accuracy score: 0.2477640342530923\n",
      "WARNING:tensorflow:From <ipython-input-43-571f84d6687a>:43: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "Test Accuracy Score:  0.2559931506849315\n",
      "2 epochs is completed\n",
      "Loss: 1.5964997\n",
      "Accuracy score: 0.24966698382492863\n",
      "Test Accuracy Score:  0.24486301369863014\n",
      "3 epochs is completed\n",
      "Loss: 1.3995006\n",
      "Accuracy score: 0.2499524262607041\n",
      "Test Accuracy Score:  0.2525684931506849\n",
      "4 epochs is completed\n",
      "Loss: 1.5170434\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "5 epochs is completed\n",
      "Loss: 1.3965294\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "6 epochs is completed\n",
      "Loss: 1.4114951\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "7 epochs is completed\n",
      "Loss: 1.3951905\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "8 epochs is completed\n",
      "Loss: 1.3854494\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "9 epochs is completed\n",
      "Loss: 1.384216\n",
      "Accuracy score: 0.2477640342530923\n",
      "Test Accuracy Score:  0.2559931506849315\n",
      "10 epochs is completed\n",
      "Loss: 1.3860407\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "11 epochs is completed\n",
      "Loss: 1.384942\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "12 epochs is completed\n",
      "Loss: 1.3852189\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "13 epochs is completed\n",
      "Loss: 1.386538\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "14 epochs is completed\n",
      "Loss: 1.3873347\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "15 epochs is completed\n",
      "Loss: 1.3875332\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "16 epochs is completed\n",
      "Loss: 1.3874346\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "17 epochs is completed\n",
      "Loss: 1.3872813\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "18 epochs is completed\n",
      "Loss: 1.3871572\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "19 epochs is completed\n",
      "Loss: 1.3870753\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "20 epochs is completed\n",
      "Loss: 1.3870233\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "21 epochs is completed\n",
      "Loss: 1.3869902\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "22 epochs is completed\n",
      "Loss: 1.3869691\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "23 epochs is completed\n",
      "Loss: 1.3869548\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "24 epochs is completed\n",
      "Loss: 1.3869427\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "25 epochs is completed\n",
      "Loss: 1.3869311\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "26 epochs is completed\n",
      "Loss: 1.3869166\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "27 epochs is completed\n",
      "Loss: 1.3868964\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "28 epochs is completed\n",
      "Loss: 1.3868651\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "29 epochs is completed\n",
      "Loss: 1.3868076\n",
      "Accuracy score: 0.252616555661275\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "30 epochs is completed\n",
      "Loss: 1.3866684\n",
      "Accuracy score: 0.2527117031398668\n",
      "Test Accuracy Score:  0.2465753424657534\n",
      "31 epochs is completed\n",
      "Loss: 1.3862574\n",
      "Accuracy score: 0.2642245480494767\n",
      "Test Accuracy Score:  0.261986301369863\n",
      "32 epochs is completed\n",
      "Loss: 1.385224\n",
      "Accuracy score: 0.2528068506184586\n",
      "Test Accuracy Score:  0.2551369863013699\n",
      "33 epochs is completed\n",
      "Loss: 1.38316\n",
      "Accuracy score: 0.2609895337773549\n",
      "Test Accuracy Score:  0.2645547945205479\n",
      "34 epochs is completed\n",
      "Loss: 1.37677\n",
      "Accuracy score: 0.29181731684110374\n",
      "Test Accuracy Score:  0.2773972602739726\n",
      "35 epochs is completed\n",
      "Loss: 1.3639371\n",
      "Accuracy score: 0.3021883920076118\n",
      "Test Accuracy Score:  0.2910958904109589\n",
      "36 epochs is completed\n",
      "Loss: 1.352309\n",
      "Accuracy score: 0.2999048525214082\n",
      "Test Accuracy Score:  0.2842465753424658\n",
      "37 epochs is completed\n",
      "Loss: 1.3461337\n",
      "Accuracy score: 0.2972407231208373\n",
      "Test Accuracy Score:  0.2851027397260274\n",
      "38 epochs is completed\n",
      "Loss: 1.3435981\n",
      "Accuracy score: 0.29762131303520456\n",
      "Test Accuracy Score:  0.2833904109589041\n",
      "39 epochs is completed\n",
      "Loss: 1.3429397\n",
      "Accuracy score: 0.29847764034253094\n",
      "Test Accuracy Score:  0.2868150684931507\n",
      "40 epochs is completed\n",
      "Loss: 1.3433102\n",
      "Accuracy score: 0.3004757373929591\n",
      "Test Accuracy Score:  0.2953767123287671\n",
      "41 epochs is completed\n",
      "Loss: 1.34428\n",
      "Accuracy score: 0.2999048525214082\n",
      "Test Accuracy Score:  0.2945205479452055\n",
      "42 epochs is completed\n",
      "Loss: 1.3455995\n",
      "Accuracy score: 0.3022835394862036\n",
      "Test Accuracy Score:  0.2962328767123288\n",
      "43 epochs is completed\n",
      "Loss: 1.347111\n",
      "Accuracy score: 0.3043767840152236\n",
      "Test Accuracy Score:  0.2979452054794521\n",
      "44 epochs is completed\n",
      "Loss: 1.3487109\n",
      "Accuracy score: 0.3049476688867745\n",
      "Test Accuracy Score:  0.2962328767123288\n",
      "45 epochs is completed\n",
      "Loss: 1.3503313\n",
      "Accuracy score: 0.30589914367269266\n",
      "Test Accuracy Score:  0.2996575342465753\n",
      "46 epochs is completed\n",
      "Loss: 1.3519285\n",
      "Accuracy score: 0.3071360608943863\n",
      "Test Accuracy Score:  0.2936643835616438\n",
      "47 epochs is completed\n",
      "Loss: 1.3534757\n",
      "Accuracy score: 0.3070409134157945\n",
      "Test Accuracy Score:  0.2936643835616438\n",
      "48 epochs is completed\n",
      "Loss: 1.3549571\n",
      "Accuracy score: 0.3069457659372027\n",
      "Test Accuracy Score:  0.2910958904109589\n",
      "49 epochs is completed\n",
      "Loss: 1.3563646\n",
      "Accuracy score: 0.30837297811607994\n",
      "Test Accuracy Score:  0.2936643835616438\n",
      "50 epochs is completed\n",
      "Loss: 1.3576944\n",
      "Accuracy score: 0.31008563273073264\n",
      "Test Accuracy Score:  0.2928082191780822\n",
      "51 epochs is completed\n",
      "Loss: 1.3589456\n",
      "Accuracy score: 0.31084681255946717\n",
      "Test Accuracy Score:  0.2945205479452055\n",
      "52 epochs is completed\n",
      "Loss: 1.3601189\n",
      "Accuracy score: 0.310941960038059\n",
      "Test Accuracy Score:  0.2970890410958904\n",
      "53 epochs is completed\n",
      "Loss: 1.3612161\n",
      "Accuracy score: 0.3110371075166508\n",
      "Test Accuracy Score:  0.2953767123287671\n",
      "54 epochs is completed\n",
      "Loss: 1.3622403\n",
      "Accuracy score: 0.3105613701236917\n",
      "Test Accuracy Score:  0.2979452054794521\n",
      "55 epochs is completed\n",
      "Loss: 1.3631954\n",
      "Accuracy score: 0.31170313986679354\n",
      "Test Accuracy Score:  0.2970890410958904\n",
      "56 epochs is completed\n",
      "Loss: 1.364087\n",
      "Accuracy score: 0.3116079923882017\n",
      "Test Accuracy Score:  0.2970890410958904\n",
      "57 epochs is completed\n",
      "Loss: 1.3649198\n",
      "Accuracy score: 0.3116079923882017\n",
      "Test Accuracy Score:  0.2979452054794521\n",
      "58 epochs is completed\n",
      "Loss: 1.365699\n",
      "Accuracy score: 0.3116079923882017\n",
      "Test Accuracy Score:  0.2970890410958904\n",
      "59 epochs is completed\n",
      "Loss: 1.3664298\n",
      "Accuracy score: 0.310941960038059\n",
      "Test Accuracy Score:  0.2970890410958904\n",
      "60 epochs is completed\n",
      "Loss: 1.367116\n",
      "Accuracy score: 0.31132254995242625\n",
      "Test Accuracy Score:  0.2945205479452055\n",
      "61 epochs is completed\n",
      "Loss: 1.3677615\n",
      "Accuracy score: 0.3116079923882017\n",
      "Test Accuracy Score:  0.2945205479452055\n",
      "62 epochs is completed\n",
      "Loss: 1.36837\n",
      "Accuracy score: 0.3116079923882017\n",
      "Test Accuracy Score:  0.2936643835616438\n",
      "63 epochs is completed\n",
      "Loss: 1.3689446\n",
      "Accuracy score: 0.3118934348239772\n",
      "Test Accuracy Score:  0.2928082191780822\n",
      "64 epochs is completed\n",
      "Loss: 1.3694875\n",
      "Accuracy score: 0.31255946717411986\n",
      "Test Accuracy Score:  0.2962328767123288\n",
      "65 epochs is completed\n",
      "Loss: 1.3700013\n",
      "Accuracy score: 0.3120837297811608\n",
      "Test Accuracy Score:  0.2945205479452055\n",
      "66 epochs is completed\n",
      "Loss: 1.3704882\n",
      "Accuracy score: 0.31341579448144624\n",
      "Test Accuracy Score:  0.2945205479452055\n",
      "67 epochs is completed\n",
      "Loss: 1.3709496\n",
      "Accuracy score: 0.3138915318744053\n",
      "Test Accuracy Score:  0.2936643835616438\n",
      "68 epochs is completed\n",
      "Loss: 1.3713878\n",
      "Accuracy score: 0.3142721217887726\n",
      "Test Accuracy Score:  0.2936643835616438\n",
      "69 epochs is completed\n",
      "Loss: 1.371804\n",
      "Accuracy score: 0.314081826831589\n",
      "Test Accuracy Score:  0.2962328767123288\n",
      "70 epochs is completed\n",
      "Loss: 1.3722003\n",
      "Accuracy score: 0.31550903901046623\n",
      "Test Accuracy Score:  0.2970890410958904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 epochs is completed\n",
      "Loss: 1.3725765\n",
      "Accuracy score: 0.315604186489058\n",
      "Test Accuracy Score:  0.2988013698630137\n",
      "72 epochs is completed\n",
      "Loss: 1.3729355\n",
      "Accuracy score: 0.3160799238820171\n",
      "Test Accuracy Score:  0.2979452054794521\n",
      "73 epochs is completed\n",
      "Loss: 1.373278\n",
      "Accuracy score: 0.3160799238820171\n",
      "Test Accuracy Score:  0.2979452054794521\n",
      "74 epochs is completed\n",
      "Loss: 1.3736048\n",
      "Accuracy score: 0.31617507136060896\n",
      "Test Accuracy Score:  0.2988013698630137\n",
      "75 epochs is completed\n",
      "Loss: 1.3739171\n",
      "Accuracy score: 0.3154138915318744\n",
      "Test Accuracy Score:  0.2996575342465753\n",
      "76 epochs is completed\n",
      "Loss: 1.3742158\n",
      "Accuracy score: 0.31550903901046623\n",
      "Test Accuracy Score:  0.2988013698630137\n",
      "77 epochs is completed\n",
      "Loss: 1.3745017\n",
      "Accuracy score: 0.3156993339676499\n",
      "Test Accuracy Score:  0.2996575342465753\n",
      "78 epochs is completed\n",
      "Loss: 1.3747753\n",
      "Accuracy score: 0.31588962892483347\n",
      "Test Accuracy Score:  0.2988013698630137\n",
      "79 epochs is completed\n",
      "Loss: 1.3750379\n",
      "Accuracy score: 0.3160799238820171\n",
      "Test Accuracy Score:  0.2979452054794521\n",
      "80 epochs is completed\n",
      "Loss: 1.3752894\n",
      "Accuracy score: 0.31579448144624167\n",
      "Test Accuracy Score:  0.2988013698630137\n",
      "81 epochs is completed\n",
      "Loss: 1.3755312\n",
      "Accuracy score: 0.3156993339676499\n",
      "Test Accuracy Score:  0.2996575342465753\n",
      "82 epochs is completed\n",
      "Loss: 1.3757639\n",
      "Accuracy score: 0.3159847764034253\n",
      "Test Accuracy Score:  0.3013698630136986\n",
      "83 epochs is completed\n",
      "Loss: 1.3759873\n",
      "Accuracy score: 0.31636536631779255\n",
      "Test Accuracy Score:  0.3022260273972603\n",
      "84 epochs is completed\n",
      "Loss: 1.3762023\n",
      "Accuracy score: 0.3168411037107517\n",
      "Test Accuracy Score:  0.3039383561643836\n",
      "85 epochs is completed\n",
      "Loss: 1.3764095\n",
      "Accuracy score: 0.3170313986679353\n",
      "Test Accuracy Score:  0.3047945205479452\n",
      "86 epochs is completed\n",
      "Loss: 1.3766092\n",
      "Accuracy score: 0.31788772597526166\n",
      "Test Accuracy Score:  0.3047945205479452\n",
      "87 epochs is completed\n",
      "Loss: 1.3768018\n",
      "Accuracy score: 0.317697431018078\n",
      "Test Accuracy Score:  0.3047945205479452\n",
      "88 epochs is completed\n",
      "Loss: 1.3769877\n",
      "Accuracy score: 0.3180780209324453\n",
      "Test Accuracy Score:  0.3039383561643836\n",
      "89 epochs is completed\n",
      "Loss: 1.3771676\n",
      "Accuracy score: 0.3185537583254044\n",
      "Test Accuracy Score:  0.3039383561643836\n",
      "90 epochs is completed\n",
      "Loss: 1.3773412\n",
      "Accuracy score: 0.31883920076117983\n",
      "Test Accuracy Score:  0.3039383561643836\n",
      "91 epochs is completed\n",
      "Loss: 1.3775091\n",
      "Accuracy score: 0.31874405328258804\n",
      "Test Accuracy Score:  0.3039383561643836\n",
      "92 epochs is completed\n",
      "Loss: 1.3776715\n",
      "Accuracy score: 0.3190294957183635\n",
      "Test Accuracy Score:  0.3047945205479452\n",
      "93 epochs is completed\n",
      "Loss: 1.3778288\n",
      "Accuracy score: 0.31912464319695527\n",
      "Test Accuracy Score:  0.3030821917808219\n",
      "94 epochs is completed\n",
      "Loss: 1.3779812\n",
      "Accuracy score: 0.31912464319695527\n",
      "Test Accuracy Score:  0.3022260273972603\n",
      "95 epochs is completed\n",
      "Loss: 1.3781292\n",
      "Accuracy score: 0.3190294957183635\n",
      "Test Accuracy Score:  0.3022260273972603\n",
      "96 epochs is completed\n",
      "Loss: 1.3782725\n",
      "Accuracy score: 0.3190294957183635\n",
      "Test Accuracy Score:  0.3030821917808219\n",
      "97 epochs is completed\n",
      "Loss: 1.3784115\n",
      "Accuracy score: 0.3192197906755471\n",
      "Test Accuracy Score:  0.3030821917808219\n",
      "98 epochs is completed\n",
      "Loss: 1.3785468\n",
      "Accuracy score: 0.3198858230256898\n",
      "Test Accuracy Score:  0.3039383561643836\n",
      "99 epochs is completed\n",
      "Loss: 1.3786781\n",
      "Accuracy score: 0.3198858230256898\n",
      "Test Accuracy Score:  0.3030821917808219\n",
      "100 epochs is completed\n",
      "Loss: 1.3788059\n",
      "Accuracy score: 0.31950523311132256\n",
      "Test Accuracy Score:  0.3030821917808219\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    acc_train,acc_test,loss_value=training(sess,train,y_out,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test\\\n",
    "                             ,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24c82c34c18>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c820b3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_test,label='Test Scores')\n",
    "plt.plot(acc_train,label='Train Scores')\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MOdel Performace is not at all good, have to try this with dimensions reductions **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions on trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/Machine_learning/savingModel/tensorflowcheckpioints/classfication_100epcohs.ckpt\n",
      "[2 2 3 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#Predictions\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"E:/Machine_learning/savingModel/tensorflowcheckpioints/classfication_100epcohs.ckpt\")\n",
    "    test_batch_data=batch_data(X_test,y_test)\n",
    "    print(sess.run(tf.arg_max(y_out,dimension=1),feed_dict={X_true:X_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
